卷积神经网络在自然语言处理的应用
希希爸爸
字数
卷积神经网络在自然语言处理的应用
转自
摘要
作为当今绝大多数计算机视觉系统的核心技术
在图像分类领域做出了巨大贡献
本文从计算机视觉的用例开始
介绍
及其在自然语言处理中的优势和发挥的作用
当我们听到
卷积神经网络
时
往往会联想到计算机视觉
在图像分类领域做出了巨大贡献
也是当今绝大多数计算机视觉系统的核心技术
从
的图像自动标签到自动驾驶汽车都在使用
最近我们开始在
自然语言处理
领域应用
并取得了一些引人注目的成果
我将在本文中归纳什么是
怎样将它们应用于
背后的直觉知识在计算机视觉的用例里更容易被理解
因此我就先从那里开始
然后慢慢过渡到自然语言处理
什么是卷积运算
对我来说
最容易的理解方式就是
把卷积想象成作用于矩阵的一个滑动窗口函数
这么说有些拗口
但是用动画显示就很直观了
的滤波器做卷积运算
图片来源
把左侧的矩阵想象成一幅黑白图像
每一个元素对应一个像素点
表示黑点
表示白点
灰度图的像素值一般是
移动窗口又称作核
滤波器或是特征检测器
这里我们使用
的滤波器
将滤波器与矩阵对应的部分逐元素相乘
然后求和
我们
平移窗口
使其扫过矩阵的所有像素
对整幅图像做卷积运算
你也许有些疑惑
刚才的操作究竟会有什么效果呢
我们就来看几个直观的例子
用邻近点像素值的均值替换其原值
实现图像模糊的效果
用邻近点像素值与自身的差值替换其原值
实现边缘检测的效果
为了直观地来理解
想想图像中平滑的那些部分
那些像素点与周围像素的颜色几乎一致
求和的结果趋近于
相当于黑色
如果有一条明显的边缘线
比如黑白分界线
那么像素值的差值将会很大
相当于白色
手册
里还有一些其它的例子
想要深入了解卷积运算的原理
我推荐阅读
写的
专题博客
什么是卷积神经网络
现在你明白了什么是卷积运算了吧
那
又是什么呢
本质上就是多层卷积运算
外加对每层的输出用非线性激活函数做转换
比如用
和
在传统的前馈神经网络中
我们把每个输入神经元与下一层的输出神经元相连接
这种方式也被称作是全连接层
或者仿射层
在
中我们不这样做
而是用输入层的卷积结果来计算输出
这相当于是
局部连接
每块局部的输入区域与输出的一个神经元相连接
对每一层应用不同的滤波器
往往是如上图所示成百上千个
然后汇总它们的结果
这里也涉及到
池化层
降采样
我会在后文做解释
在训练阶段
基于你想完成的任务自动学习滤波器的权重值
举个例子
在图像分类问题中
第一层
模型或许能学会从原始像素点检测到一些边缘线条
然后根据边缘线条在第二层检测出一些简单的形状
然后基于这些形状检测出更高级的特征
比如脸部轮廓等
最后一层是利用这些高级特征的一个分类器
这种计算方式有两点值得我们注意
位置不变性和组合性
比如说你想对图片中是否包含大象做分类
因为滤波器是在全图范围内平移
所以并不用关心大象究竟在图片的什么位置
事实上
池化也有助于平移
旋转和缩放的不变性
它对克服缩放因素的效果尤其好
第二个关键因素是
局部
组合性
每个滤波器对一小块局部区域的低级特征组合形成更高级的特征表示
这也是
对计算机视觉作用巨大的原因
我们可以很直观地理解
线条由像素点构成
基本形状又由线条构成
更复杂的物体又源自基本的形状
那么
如何将它们用于
呢
任务的输入不再是像素点了
大多数情况下是以矩阵表示的句子或者文档
矩阵的每一行对应于一个分词元素
一般是一个单词
也可以是一个字符
也就是说每一行是表示一个单词的向量
通常
这些向量都是
一种底维度表示
的形式
如
和
但是也可以用
向量的形式
也即根据词在词表中的索引
若是用
维的词向量表示一句
个单词的句子
我们将得到一个
维的矩阵作为输入
这个矩阵相当于是一幅
图像
在计算机视觉的例子里
我们的滤波器每次只对图像的一小块区域运算
但在处理自然语言时滤波器通常覆盖上下几行
几个词
因此
滤波器的宽度也就和输入矩阵的宽度相等了
尽管高度
或者区域大小可以随意调整
但一般滑动窗口的覆盖范围是
行
综上所述
处理自然语言的卷积神经网络结构是这样的
花几分钟时间理解这张图片
以及维度是如何变化的
你可以先暂时忽略池化操作
我们在稍后会解释它
用于句子分类器的卷积神经网络
结构示意图
这里我们对滤波器设置了三种尺寸
和
行
每种尺寸各有两种滤波器
每个滤波器对句子矩阵做卷积运算
得到
不同程度的
特征字典
然后对每个特征字典做最大值池化
也就是只记录每个特征字典的最大值
这样
就由六个字典生成了一串单变量特征向量
然后这六个特征拼接形成一个特征向量
传给网络的倒数第二层
最后的
层以这个特征向量作为输入
用其来对句子做分类
我们假设这里是二分类问题
因此得到两个可能的输出状态
来源
计算机视觉完美的直观感受这里还存在吗
位置不变性和局部组合性对图像来说很直观
但对
却并非如此
你也许会很在意一个词在句子中出现的位置
相邻的像素点很有可能是相关联的
都是物体的同一部分
但单词并不总是如此
在很多种语言里
短语之间会被许多其它词所隔离
同样
组合性也不见得明显
单词显然是以某些方式组合的
比如形容词修饰名词
但若是想理解更高级特征真正要表达的含义是什么
并不像计算机视觉那么明显了
由此看来
卷积神经网络似乎并不适合用来处理
任务
递归神经网络
更直观一些
它们模仿我们人类处理语言的方式
至少是我们自己所认为的方式
从左到右的顺序阅读
庆幸的是
这并不意味着
没有效果
所有的模型都是错的
只是一些能被利用
实际上
对
问题的效果非常理想
正如
词袋模型
它明显是基于错误假设的过于简化模型
但这不影响它多年来一直被作为
的标准方法
并且取得了不错的效果
的主要特点在于速度快
非常的快
卷积运算是计算机图像的核心部分
在
级别的硬件层实现
相比于
表征方式的效率也更胜一筹
由于词典庞大
任何超过
的计算开销就会非常的大
即使
也最多不超过
卷积滤波器能自动学习好的表示方式
不需要用整个词表来表征
那么用尺寸大于
行的滤波器完全合情合理了
我个人认为许多在第一层学到的滤波器扑捉到的特征与
非常相似
但不局限
但是以更紧凑的方式表征
的超参数
在解释如何将
用于
任务之前
先来看一下构建
网络时需要面临的几个选择
希望这能帮助你更好地理解相关文献
窄卷积
宽卷积
在上文中解释卷积运算的时候
我忽略了如何使用滤波器的一个小细节
在矩阵的中部使用
的滤波器没有问题
在矩阵的边缘该怎么办呢
左上角的元素没有顶部和左侧相邻的元素
该如何滤波呢
解决的办法是采用补零法
所有落在矩阵范围之外的元素值都默认为
这样就可以对输入矩阵的每一个元素做滤波了
输出一个同样大小或是更大的矩阵
补零法又被称为是宽卷积
不使用补零的方法则被称为窄卷积
的例子如图所示
窄卷积
宽卷积
滤波器长度为
输入长度为
来源
当滤波器长度相对输入向量的长度较大时
你会发现宽卷积很有用
或者说很有必要
在上图中
窄卷积输出的长度是
宽卷积输出的长度是
一般形式为
步长
卷积运算的另一个超参数是
步长
即每一次滤波器平移的距离
上面所有例子中的步长都是
相邻两个滤波器有重叠
步长越大
则用到的滤波器越少
输出的值也越少
下图来自斯坦福的
课程网页
分别是步长为
和
的情况
卷积步长
左侧
步长为
右侧
步长为
来源
在文献中我们常常见到的步长是
但
选择更大的步长会让模型更接近于
递归神经网络
其结构就像是一棵树
池化层
卷积神经网络的一个重要概念就是池化层
一般是在卷积层之后
池化层对输入做降采样
常用的池化做法是对每个滤波器的输出求最大值
我们并不需要对整个矩阵都做池化
可以只对某个窗口区间做池化
例如
下图所示的是
窗口的最大值池化
在
里
我们通常对整个输出做池化
每个滤波器只有一个输出值
的最大池化
来源
为什么要池化呢
有许多原因
池化的特点之一就是它输出一个固定大小的矩阵
这对分类问题很有必要
例如
如果你用了
个滤波器
并对每个输出使用最大池化
那么无论滤波器的尺寸是多大
也无论输入数据的维度如何变化
你都将得到一个
维的输出
这让你可以应用不同长度的句子和不同大小的滤波器
但总是得到一个相同维度的输出结果
传入下一层的分类器
池化还能降低输出结果的维度
理想情况下
却能保留显著的特征
你可以认为每个滤波器都是检测一种特定的特征
例如
检测句子是否包含诸如
等否定意思
如果这个短语在句子中的某个位置出现
那么对应位置的滤波器的输出值将会非常大
而在其它位置的输出值非常小
通过采用取最大值的方式
能将某个特征是否出现在句子中的信息保留下来
但是无法确定它究竟在句子的哪个位置出现
这个信息出现的位置真的很重要吗
确实是的
它有点类似于一组
模型的行为
尽管丢失了关于位置的全局信息
在句子中的大致位置
但是滤波器捕捉到的局部信息却被保留下来了
比如
和
的意思就大相径庭
在图像识别领域
池化还能提供平移和旋转不变性
若对某个区域做了池化
即使图像平移
旋转几个像素
得到的输出值也基本一样
因为每次最大值运算得到的结果总是一样的
通道
我们需要了解的最后一个概念是通道
通道即是输入数据的不同
视角
比如说
做图像识别时一般会用到
通道
红绿蓝
你可以对每个通道做卷积运算
赋予相同或不同的权值
你也同样可以把
想象成有许多个通道
把不同类的词向量表征
例如
和
看做是独立的通道
或是把不同语言版本的同一句话看作是一个通道
卷积神经网络在自然语言处理的应用
我们接下来看看卷积神经网络模型在自然语言处理领域的实际应用
我试图去概括一些研究成果
希望至少能够涵盖大部分主流的成果
难免也会遗漏其它一些有意思的应用
请在评论区提醒我
最适合
的莫过于分类任务
如语义分析
垃圾邮件检测和话题分类
卷积运算和池化会丢失局部区域某些单词的顺序信息
因此纯
的结构框架不太适用于
和
等顺序标签任务
也不是不可能
你可以尝试输入位置相关的特征
文献
在不同的分类数据集上评估
模型
主要是基于语义分析和话题分类任务
模型在各个数据集上的表现非常出色
甚至有个别刷新了目前最好的结果
令人惊讶的是
这篇文章采用的网络结构非常简单
但效果相当棒
输入层是一个表示句子的矩阵
每一行是
词向量
接着是由若干个滤波器组成的卷积层
然后是最大池化层
最后是
分类器
该论文也尝试了两种不同形式的通道
分别是静态和动态词向量
其中一个通道在训练时动态调整而另一个不变
文献
中提到了一个类似的结构
但更复杂一些
文献
在网络中又额外添加了一个层
用于语义聚类
卷积神经网络用来语句分类
文献
从原始数据训练
模型
不需要预训练得到
或
等词向量表征
它直接对
向量进行卷积运算
作者对输入数据采用了节省空间的类似词袋表征方式
以减少网络需要学习的参数个数
在文献
中作者用了
学习得到的非监督式
来扩展模型
预测文字区域的上下文内容
这些论文中提到的方法对处理长文本
比如影评
非常有效
但对短文本
比如推特
的效果还不清楚
凭我的直觉
对短文本使用预训练的词向量应该能比长文本取得更好的效果
搭建一个
模型结构需要选择许多个超参数
我在上文中已经提到了一些
输入表征
卷积滤波器的数量和尺寸
池化策略
最大值
平均值
以及激活函数
文献
通过多次重复实验
比较了不同超参数对
模型结构在性能和稳定性方面的影响
如果你想自己实现一个
用于文本分类
可以借鉴该论文的结果
其主要的结论有最大池化效果总是好于平均池化
选择理想的滤波器尺寸很重要
但也根据任务而定需
正则化在
任务中的作用并不明显
需要注意的一点是该研究所用文本集里的文本长度都相近
因此若是要处理不同长度的文本
上述结论可能不具有指导意义
文献
探索了
在关系挖掘和关系分类任务中的应用
除了词向量表征之外
作者还把词与词的相对位置作为卷积层的输入值
这个模型假设了所有文本元素的位置已知
每个输入样本只包含一种关系
文献
和文献
使用的模型类似
来自微软研究院的文献
和
介绍了
在
的另一种有趣的应用方式
这两篇论文介绍了如何学习将句子表示成包含语义的结构
它能被用来做信息检索
论文中给出的例子是基于用户当前的阅读内容
为其推荐其它感兴趣的文档
句子的表征是基于搜索引擎的日志数据训练得到的
大多数
模型以这样或是那样的训练方式来学习单词和句子的词向量表征
它是训练过程的一部分
并不是所有论文都关注这一步训练过程
也并不在乎学到的表征意义有多大
文献
介绍了用
模型对
的日志打标签
这些学到的词向量随后又被成功应用于另一个任务
基于点击日志给用户推荐感兴趣的文章
字符层面的
模型
至此
所有的模型表征都是在单词的层面上
另外有一些团队则研究如何将
模型直接用于字符
文献
学到了字符层面的向量表征
将它们与预训练的词向量结合
用来给语音打标签
文献
和
研究了直接用
模型直接从字符学习
而不必预训练词向量了
值得注意的是
作者使用了一个相对较深的网络结构
共有
层
用来完成语义分析和文本分类任务
结果显示
用字符级输入直接在大规模数据集
百万级
上学习的效果非常好
但用简单模型在小数据集
十万级
上的学习效果一般
文献
是关于字符级卷积运算在语言建模方面的应用
将字符级
模型的输出作为
模型每一步的输入
同一个模型用于不同的语言
令人惊讶的是
上面所有论文几乎都是发表于近两年
显然
模型在
领域已经有了出色的表现
新成果和顶级系统还在层出不穷地出现
若有疑问或是反馈
请在评论区留言
谢谢阅读
参考文献
原文链接
译者
赵屹华
审核
刘翔宇
朱正贵
责编
周建丁
原创
翻译投稿请联系
微信号
译者简介
赵屹华
计算广告工程师
搜狗
前生物医学工程师
关注推荐算法
机器学习领域
第九届中国大数据技术大会
将于
年
月
日在北京隆重举办
在主会之外
会议还设立了
大分论坛
包含数据库
深度学习
推荐系统
安全等
大技术论坛
金融
制造业
交通旅游
互联网
医疗健康
教育等
大应用论坛和
大热点议题论坛
票价折扣中预购从速
本文为
编译整理
未经允许不得转载
如需转载请联系
换成
机器学习
著作权归作者所有
举报文章
希希爸爸
我幻想的旅行地是一座山
山上堆着皑皑的白雪
通向大山的是一条绵延弯曲的马路
总是望不到尽头
有一天我会开着敞篷车
带着你驶向幸福
下载
生成长微博图片
更多分享
卷积神经网络
经典模型整理
首先是再次对卷积神经网络的介绍
更深入的理解
卷积神经网络是人工神经网络的一种
已成为当前语音分析和图像识别领域的研究热点
它的权值共享网络结构使之更类似于生物神经网络
降低了网络模
卷积神经网络
在自然语言处理中的应用
序言
在文本分类中取得了不俗的结果
而运用在这里的卷积可以分为
甚至是
的
我们知道
一般用来做图像
图像是可以通过预处理
将每幅照片都处理成一样的
的
也就是
和
具有一样的像素值
然后用一个
在图像上去滑动做卷
木豆
一步一步学用
构建卷积神经网络
摘要
本文主要和大家分享如何使用
从头开始构建和训练卷积神经网络
这样就可以将这个知识作为一个构建块来创造有趣的深度学习应用程序了
简介
在过去
我写的主要都是
传统类
的机器学习文章
如朴素贝叶斯分类
逻辑回归和
算法
在
阿里云云栖社区
机器视角
长文揭秘图像处理和卷积神经网络架构
近日
在
上发表了一篇题为
的文章
对用于图像识别和分类的卷积神经网络架构作了
译
用于语义分割的全卷积网络
题目
用于语义分割的全卷积网络
文章链接
转载请注明出处
译
用于语义分割的全卷积网络
微框架
的安装
安装
项目安装
你好
类型转换
语言类型转换可以判断实例的类型
也可以用于检测实例类型是否属于其父类或者子类的实例
中类型转换使用
和
操作符实现
用于检测值的类型
用于转换类型
类型转换也可以用来检查一个类是否实现了某个协议
定义一个类层次
以下定义
零度
不结冰
漂洋过海来看你
我来到你的城市
你却远走他乡
我对这座城市有了感情
你却要另寻一片土地安家
我漂洋过海来看你
然而看到你时
我已不再爱你
白洋菲
读图
乍一看
你以为这是我熟人吧
其实不是
这是路人
两个小女孩在那玩吃饭的游戏
摆好了盘子放好了刀叉
抱着手的小女孩
漫不经心的
看着白衣服女孩子摆弄餐具
白衣服眼神专注
扫街时候
你敢不敢对人拍
这是亲和力和胆子问题
看到可能的好照片
反应够不够快
相机快门按不按的下去
这
汉口张叔叔
与母亲的日常
我想写一些我与母亲的日常
也仅仅只是日常而已
触发我写文章的引头是这两天和母亲频繁的磕磕绊绊
我想下文就直接称呼为老妈
母亲念起来太疏离了
不要误会
我并不是要探讨严重的母女问题
老妈老爸三个月前搬来上海与我同住
原因无意多说
我的租房只有一个卧室
因为临时需要也无意去
木点点