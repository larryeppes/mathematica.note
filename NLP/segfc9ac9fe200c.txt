一步一步学用
构建卷积神经网络
阿里云云栖社区
字数
摘要
本文主要和大家分享如何使用
从头开始构建和训练卷积神经网络
这样就可以将这个知识作为一个构建块来创造有趣的深度学习应用程序了
简介
在过去
我写的主要都是
传统类
的机器学习文章
如朴素贝叶斯分类
逻辑回归和
算法
在过去的一年中
我一直在研究深度学习技术
因此
我想和大家分享一下如何使用
从头开始构建和训练卷积神经网络
这样
我们以后就可以将这个知识作为一个构建块来创造有趣的深度学习应用程序了
为此
你需要安装
你还应该对
编程和卷积神经网络背后的理论有一个基本的了解
安装完
之后
你可以在不依赖
的情况下运行一个较小的神经网络
但对于更深层次的神经网络
就需要用到
的计算能力了
在互联网上有很多解释卷积神经网络工作原理方面的网站和课程
其中有一些还是很不错的
图文并茂
易于理解
我在这里就不再解释相同的东西
所以在开始阅读下文之前
请提前了解卷积神经网络的工作原理
例如
什么是卷积层
卷积层的过滤器是什么
什么是激活层
层
应用最广泛的
型激活或
什么是池层
最大池
平均池
什么是
随机梯度下降的工作原理是什么
本文内容如下
基础
常数和变量
中的图和会话
占位符和
中的神经网络
介绍
数据加载
创建一个简单的一层神经网络
的多个方面
创建
卷积神经网络
影响层输出大小的参数
调整
架构
学习速率和优化器的影响
中的深度神经网络
性能
结语
基础
在这里
我将向以前从未使用过
的人做一个简单的介绍
如果你想要立即开始构建神经网络
或者已经熟悉
可以直接跳到第
节
常量与变量
中最基本的单元是常量
变量和占位符
和
之间的区别很清楚
一个常量有着恒定不变的值
一旦设置了它
它的值不能被改变
而变量的值可以在设置完成后改变
但变量的数据类型和形状无法改变
除了
和
能够创建一个初始值为
或
的张量之外
还有一个
函数
它能够创建一个包含多个随机值的张量
这些随机值是从正态分布中随机抽取的
默认的分布均值为
标准差为
另外还有一个
函数
它创建了一个包含从截断的正态分布中随机抽取的值的张量
其中下上限是标准偏差的两倍
有了这些知识
我们就可以创建用于神经网络的权重矩阵和偏差向量了
中的图与会话
在
中
所有不同的变量以及对这些变量的操作都保存在图
中
在构建了一个包含针对模型的所有计算步骤的图之后
就可以在会话
中运行这个图了
会话可以跨
和
分配所有的计算
占位符
与
我们已经看到了用于创建常量和变量的各种形式
中也有占位符
它不需要初始值
仅用于分配必要的内存空间
在一个会话中
这些占位符可以通过
填入
外部
数据
以下是占位符的使用示例
中的神经网络
简介
包含神经网络的图
如上图所示
应包含以下步骤
输入数据集
训练数据集和标签
测试数据集和标签
以及验证数据集和标签
测试和验证数据集可以放在
中
而训练数据集被放在
中
这样它可以在训练期间分批输入
随机梯度下降
神经网络
模型
及其所有的层
这可以是一个简单的完全连接的神经网络
仅由一层组成
或者由
层组成的更复杂的神经网络
权重矩阵
和
偏差矢量
以适当的形状进行定义和初始化
每层一个权重矩阵和偏差矢量
损失
值
模型可以输出分对数矢量
估计的训练标签
并通过将分对数与实际标签进行比较
计算出损失值
具有交叉熵函数的
损失值表示估计训练标签与实际训练标签的接近程度
并用于更新权重值
优化器
它用于将计算得到的损失值来更新反向传播算法中的权重和偏差
数据加载
下面我们来加载用于训练和测试神经网络的数据集
为此
我们要下载
和
数据集
数据集包含了
万个手写数字图像
其中每个图像大小为
灰度
数据集也包含了
万个图像
个通道
大小为
包含
个不同的物体
飞机
汽车
鸟
猫
鹿
狗
青蛙
马
船
卡车
由于两个数据集中都有
个不同的对象
所以这两个数据集都包含
个标签
首先
我们来定义一些方便载入数据和格式化数据的方法
这些方法可用于对标签进行独热码编码
将数据加载到随机数组中
扁平化矩阵
因为完全连接的网络需要一个扁平矩阵作为输入
在我们定义了这些必要的函数之后
我们就可以这样加载
和
数据集了
你可以从
的网站下载
数据集
下载并解压缩之后
可以使用
工具来加载数据
创建一个简单的一层神经网络
神经网络最简单的形式是一层线性全连接神经网络
在数学上它由一个矩阵乘法组成
最好是在
中从这样一个简单的
开始
然后再去研究更复杂的神经网络
当我们研究那些更复杂的神经网络的时候
只是图的模型
步骤
和权重
步骤
发生了改变
其他步骤仍然保持不变
我们可以按照如下代码制作一层
在图中
我们加载数据
定义权重矩阵和模型
从分对数矢量中计算损失值
并将其传递给优化器
该优化器将更新迭代
次数的权重
在上述完全连接的
中
我们使用了梯度下降优化器来优化权重
然而
有很多不同的优化器可用于
最常用的优化器有
和
所以如果你正在构建一个
的话
我建议你试试这些
有一篇不错的博文介绍了不同优化器之间的区别
通过这篇文章
你可以更详细地了解它们
的几个方面
包含许多层
这意味着可以通过不同的抽象级别来完成相同的操作
这里有一个简单的例子
操作
也可以这样来实现
这是
中最明显的一层
它是一个具有高度抽象性的层
可以很容易地创建由许多不同层组成的神经网络
例如
或
函数用于创建卷积和完全连接的层
通过这些函数
可以将层数
过滤器的大小或深度
激活函数的类型等指定为参数
然后
权重矩阵和偏置矩阵会自动创建
一起创建的还有激活函数和丢弃正则化层
例如
通过使用
层
下面这些代码
可以替换为
可以看到
我们不需要定义权重
偏差或激活函数
尤其是在你建立一个具有很多层的神经网络的时候
这样可以保持代码的清晰和整洁
然而
如果你刚刚接触
的话
学习如何构建不同种类的神经网络并不合适
因为
做了所有的工作
因此
我们不会在本文中使用层
但是一旦你完全理解了如何在
中构建神经网络
我还是建议你使用它
创建
卷积神经网络
下面我们将开始构建更多层的神经网络
例如
卷积神经网络
架构最早是在
年由
见论文
提出的
它是最早的
之一
专门用于对手写数字进行分类
尽管它在由大小为
的灰度图像组成的
数据集上运行良好
但是如果用于其他包含更多图片
更大分辨率以及更多类别的数据集时
它的性能会低很多
对于这些较大的数据集
更深的
如
或
会表现得更好
但由于
架构仅由
个层构成
因此
学习如何构建
是一个很好的起点
架构如下图所示
我们可以看到
它由
个层组成
第
层
卷积层
包含
型激活函数
然后是平均池层
第
层
卷积层
包含
型激活函数
然后是平均池层
第
层
一个完全连接的网络
型激活
第
层
一个完全连接的网络
型激活
第
层
输出层
这意味着我们需要创建
个权重和偏差矩阵
我们的模型将由
行代码组成
个层
个池
个激活函数
个扁平层
由于这个还是有一些代码量的
因此最好在图之外的一个单独函数中定义这些代码
由于变量和模型是单独定义的
我们可以稍稍调整一下图
以便让它使用这些权重和模型
而不是以前的完全连接的
我们可以看到
架构在
数据集上的表现比简单的完全连接的
更好
影响层输出大小的参数
一般来说
神经网络的层数越多越好
我们可以添加更多的层
修改激活函数和池层
修改学习速率
以看看每个步骤是如何影响性能的
由于
层的输入是
层的输出
我们需要知道不同的参数是如何影响
层的输出大小的
要了解这一点
可以看看
函数
它有四个参数
输入图像
维度为
的
张量
权重矩阵
维度为
的
张量
每个维度的步幅数
填充
这四个参数决定了输出图像的大小
前两个参数分别是包含一批输入图像的
张量和包含卷积滤波器权重的
张量
第三个参数是卷积的步幅
即卷积滤波器在四维的每一个维度中应该跳过多少个位置
这四个维度中的第一个维度表示图像批次中的图像编号
由于我们不想跳过任何图像
因此始终为
最后一个维度表示图像深度
不是色彩的通道数
灰度为
为
由于我们不想跳过任何颜色通道
所以这个也总是为
第二和第三维度表示
和
方向上的步幅
图像宽度和高度
如果要应用步幅
则这些是过滤器应跳过的位置的维度
因此
对于步幅为
我们必须将步幅参数设置为
如果我们希望步幅为
则将其设置为
以此类推
最后一个参数表示
是否应该对图像用零进行填充
以确保对于步幅为
的输出尺寸不会改变
如果
则图像用零填充
并且输出大小不会改变
如果
则不填充
下面我们可以看到通过图像
大小为
扫描的卷积滤波器
滤波器大小为
的两个示例
在左侧
填充参数设置为
图像用零填充
最后
行
列包含在输出图像中
在右侧
填充参数设置为
图像不用零填充
最后
行
列不包括在输出图像中
我们可以看到
如果没有用零填充
则不包括最后四个单元格
因为卷积滤波器已经到达
非零填充
图像的末尾
这意味着
对于
的输入大小
输出大小变为
如果
则输出大小为
如果在扫描图像时记下过滤器在图像上的位置
为简单起见
只有
方向
那么这一点就变得更加清晰了
如果步幅为
则
位置为
等等
如果步幅为
则
位置为
等等
如果图像大小为
滤镜大小为
并且步长
到
那么我们可以得到下面这个表
可以看到
对于步幅为
零填充输出图像大小为
如果非零填充
则输出图像大小变为
对于步幅为
的过滤器
这几个数字分别为
和
对于步幅为
的过滤器
分别为
和
以此类推
对于任意一个步幅
滤波器尺寸
图像尺寸
和填充尺寸
输出尺寸将为
如果在
中
则分子加起来恒等于
输出大小仅由步幅
决定
调整
的架构
在原始论文中
架构使用了
形激活函数和平均池
然而
现在
使用
激活函数则更为常见
所以
我们来稍稍修改一下
看看是否能够提高准确性
我们将称之为类
架构
主要区别是我们使用了
激活函数而不是
形激活函数
除了激活函数
我们还可以改变使用的优化器
看看不同的优化器对精度的影响
学习速率和优化器的影响
让我们来看看这些
在
和
数据集上的表现
在上面的图中
测试集的精度是迭代次数的函数
左侧为一层完全连接的
中间为
右侧为类
可以看到
在
数据集上表现得非常好
这并不是一个大惊喜
因为它专门就是为分类手写数字而设计的
数据集很小
并没有太大的挑战性
所以即使是一个完全连接的网络也表现的很好
然而
在
数据集上
的性能显着下降
精度下降到了
左右
为了提高精度
我们可以通过应用正则化或学习速率衰减来改变优化器
或者微调神经网络
可以看到
和
的性能比
更好
这些都是自适应优化器
其性能通常比
更好
但需要更多的计算能力
通过
正则化或指数速率衰减
我们可能会得到更搞的准确性
但是要获得更好的结果
我们需要进一步研究
中的深度神经网络
到目前为止
我们已经看到了
架构
包含两个卷积层
紧接着的是完全连接的层
因此可以称为浅层神经网络
那时候
年
还没有被用来进行计算
而且
的功能也没有那么强大
所以
在当时
两个卷积层已经算是相当具有创新意义了
后来
很多其他类型的卷积神经网络被设计出来
你可以在这里查看详细信息
比如
由
开发的非常有名的
架构
年
层的
以及
层的
在
年
发布了一个包含初始模块的
层的
而微软亚洲研究院构建了一个
层的
被称为
现在
根据我们目前已经学到的知识
我们来看一下如何在
中创建
和
架构
虽然
是第一个
但它被认为是一个浅层神经网络
它在由大小为
的灰度图像组成的
数据集上运行良好
但是当我们尝试分类更大
分辨率更好
类别更多的图像时
性能就会下降
第一个深度
于
年推出
称为
其创始人为
和
与最近的架构相比
可以算是简单的了
但在当时它确实非常成功
它以令人难以置信的
的测试错误率赢得了
比赛
亚军的误差为
并在全球深度学习和人工智能领域掀起了一场革命
它包括
个卷积层
个最大池化层
个完全连接层和
个丢弃层
整体架构如下所示
第
层
大小为
的输入图像
第
层
具有
个滤波器
的卷积层
大小为
步长为
它包含
激活函数
紧接着的是最大池化层和本地响应归一化层
第
层
具有大小为
的
个滤波器
且步幅为
的卷积层
它包含
激活函数
紧接着的还是最大池化层和本地响应归一化层
第
层
具有
个滤波器的卷积层
尺寸为
步幅为
它包含
激活函数
第
层
与第
层相同
第
层
具有大小为
的
个滤波器
且步幅为
的卷积层
它包含
激活函数
第
层
这些卷积层之后是完全连接层
每个层具有
个神经元
在原始论文中
他们对
个类别的数据集进行分类
但是我们将使用具有
个不同类别
的花卉
的
数据集
请注意
由于这些数据集中的图像太小
因此无法在
或
数据集上使用此
或其他的深度
正如我们以前看到的
一个池化层
或一个步幅为
的卷积层
将图像大小减小了
倍
具有
个最大池化层和一个步长为
的卷积层
这意味着原始图像尺寸会缩小
数据集中的图像将简单地缩小到尺寸小于
因此
我们需要加载具有较大图像的数据集
最好是
如原始文件所示
个类别的花卉数据集
又名
数据集是最理想的
因为它包含了这个大小的图像
让我们试着在
中创建权重矩阵和不同的层
正如我们之前看到的
我们需要跟层数一样多的权重矩阵和偏差矢量
并且每个权重矩阵的大小应该与其所属层的过滤器的大小相对应
现在我们可以修改
模型来使用
模型的权重和层次来对图像进行分类
于
年由牛津大学的
和
创建出来
它包含了更多的层
层
但是每一层的设计更为简单
所有卷积层都具有
以及步长为
的过滤器
并且所有最大池化层的步长都为
所以它是一个更深的
但更简单
它存在不同的配置
层或
层
这两种不同配置之间的区别是在第
第
和第
最大池化层之后对
或
个卷积层的使用
见下文
配置为
层
配置
的结果似乎更好
所以我们试着在
中创建它
性能
作为比较
看一下对包含了较大图片的
数据集的
性能
结语
相关代码可以在我的
库中获得
因此可以随意在自己的数据集上使用它
在深度学习的世界中还有更多的知识可以去探索
循环神经网络
基于区域的
加强学习等等
在未来的博客文章中
我将构建这些类型的神经网络
并基于我们已经学到的知识构建更有意思的应用程序
文章原标题
作者
译者
夏天
审校
主题曲
日记本
著作权归作者所有
举报文章
阿里云云栖社区
汇集阿里技术精粹
欢迎关注
官方微博
阿里云云栖社区
官方微信号
下载
生成长微博图片
更多分享
深入浅出
四
卷积神经网络
作者
郑泽宇
前线出品
年
月
日
正式对外发布
版本
并保证本次的发布版本
接口完全满足生产环境稳定性要求
这是
的一个重要里程碑
标志着它可以正式在生产环
前线
卷积神经网络
介绍
先前的教程展示了一个简单的线性模型
对
数据集中手写数字的识别率达到了
在这个教程中
我们会在
中实现一个简单的卷积神经网络
它能达到大约
的分类准确率
如果你做了一些建议的练习
准确率还可能更高
卷积神经网络在一张输入图片上移
课程笔记五
卷积神经网络
卷积神经网络类似于一般的神经网络
由可学习的权重和误差组成
每一个神经元接受一些输入
完成一些非线性的操作
整个神经网络完成了一个可微的打分函数
从图像点到分类得分
在全连接或者最后一层他们也有一个损失函数
而卷积神经网络中有明确的假设那就是输入时图像
这代表了网络机构具有
彭岩
重磅
神经网络浅讲
从神经元到深度学习
神经网络是一门重要的机器学习技术
它是目前最为火热的研究方向
深度学习的基础
学习神经网络不仅可以让你掌握一门强大的机器学习方法
同时也可以更好地帮助你理解深度学习技术
本文以一种简单的
循序的方式讲解神经网络
适合对神经网络了解不多的同学
本文对阅读没有一定的前提要求
但
神经网络
转载的他人的文章
适合神经网络刚开始学习的人
神经网络浅讲
从神经元到深度学习
神经网络是一门重要的机器学习技术
它是目前最为火热的研究方向
深度学习的基础
学习神经网络
短篇小说
隔壁老刘
原创诗文组合
文
三绅皮具叶明增
起首语
有诗证曰
南乡子
叹老刘
隔壁某名刘
拼搏勤工四十秋
谁道俗夫身就贱
千谋
生取人间百富流
浮世一蚍蝼
究竟阎王簿上囚
缘里本无由他走
何求
盼去思来命却休
正文
一
隔壁老刘今年五十九虚岁
在某国营化工机
茶老皮匠
纷扰
一柱香
两盏茶
晨露伴晚霞之光
倾尽一世空繁华
连阴雨
续惆怅
滴穿世人烟雨泪
却到无处话凄凉
情人扣
锁心扉
纷扰两心空增悲
奈何缪时枉人为
芬外饶
如果不能好好玩耍
那就分手吧
如果每一段感情都能想我们所预料的那样发展下去就好了
仔细一想也不行
谁又知道对方所想的是什么呢
遇到分岔路口
这段感情又该听谁的指挥呢
我最近和我一直以来玩的很好的朋友
我曾经视为知己的朋友
闹翻了
更搞笑的是
我们现在合租在一起
每天抬头不见低头
等等等等
鸡年吉祥
我的小幸运
年的春节
元宵节都陆续的结束了
总感觉要写点什么
留下点东西
今年回家过年感觉特别幸运
农历
下午到家
缓冲了下
接着直接通宵帮我妈做年糕
整个流程我和我爸两个人搞下来
我妈连续两个通宵了终于挺不住去睡了
一直做到凌晨
点
所有的年糕都卖完
我居然一点都不困
尤的世界
完美不重要
完成才重要
记第一次线上学习复盘总结
给这次复盘总结取这个标题
是有私心的
就像赐予了我第一阶段做的不好而定制的一个完美借口
这样一来
心会安
从
百日营正式开营
倒计时
天
到今日
第一阶段总结截止
倒计时
天
共计
天
发生了什么改变了什么收获了什么
小花酱乜